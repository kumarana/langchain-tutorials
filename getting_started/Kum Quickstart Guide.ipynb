{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed4da4d",
   "metadata": {},
   "source": [
    "## Quickstart Guide\n",
    "https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05530b1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.153-py3-none-any.whl (696 kB)\n",
      "     ------------------------------------- 696.4/696.4 kB 22.1 MB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "     ---------------------------------------- 143.2/143.2 kB ? eta 0:00:00\n",
      "Collecting SQLAlchemy<3,>1.4\n",
      "  Downloading SQLAlchemy-2.0.11-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 41.6 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "     ------------------------------------- 317.2/317.2 kB 19.2 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Downloading numexpr-2.8.4-cp311-cp311-win_amd64.whl (92 kB)\n",
      "     ---------------------------------------- 92.7/92.7 kB ? eta 0:00:00\n",
      "Collecting numpy<2,>=1\n",
      "  Downloading numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     --------------------------------------- 14.8/14.8 MB 12.3 MB/s eta 0:00:00\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.0/90.0 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.7 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.5/62.5 kB ? eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting tqdm>=4.48.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.7/96.7 kB ? eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "     ---------------------------------------- 60.2/60.2 kB ? eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.1/49.1 kB ? eta 0:00:00\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     ---------------------------------------- 140.9/140.9 kB ? eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp311-cp311-win_amd64.whl (192 kB)\n",
      "     ---------------------------------------- 192.5/192.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.48.0->langchain) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, tenacity, PyYAML, numpy, mypy-extensions, multidict, marshmallow, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, typing-inspect, SQLAlchemy, requests, pydantic, numexpr, marshmallow-enum, aiosignal, openapi-schema-pydantic, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed PyYAML-6.0 SQLAlchemy-2.0.11 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2022.12.7 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 greenlet-2.0.2 idna-3.4 langchain-0.0.153 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 numpy-1.24.3 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 requests-2.29.0 tenacity-8.2.2 tqdm-4.65.0 typing-extensions-4.5.0 typing-inspect-0.8.0 urllib3-1.26.15 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b556fc2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.5)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c07fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126a6a1",
   "metadata": {},
   "source": [
    "# Building A Language Model Application\n",
    "### LLMS: Get predictions from a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bef95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3596e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ebe6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Chennai, India\n",
      "2. Kolkata, India\n",
      "3. New Delhi, India\n",
      "4. Singapore\n",
      "5. Bangkok, Thailand\n"
     ]
    }
   ],
   "source": [
    "text = \"What are 5 vacation destinations for someone who likes to eat idly?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657e1e9",
   "metadata": {},
   "source": [
    "### Prompt Templates: Manage prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168f2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d6d3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "160f8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat parotta?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"parotta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4309f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Chennai, India - home of the delicious Mumbai-style parotta\n",
      "2. Penang, Malaysia - renowned for its flavorful parotta\n",
      "3. Hyderabad, India - the birthplace of parotta\n",
      "4. Bangkok, Thailand - for its street-style parotta\n",
      "5. Kuala Lumpur, Malaysia - for its aromatic and crunchy parotta\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"parotta\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0c523",
   "metadata": {},
   "source": [
    "### Chains: Combine LLMs and prompts in multi-step workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a34ff024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffbdf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7efda77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b08b76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Chennai, India\n",
      "2. Bangalore, India\n",
      "3. Hyderabad, India\n",
      "4. Mumbai, India\n",
      "5. Colombo, Sri Lanka\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"dosa\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850668f0",
   "metadata": {},
   "source": [
    "### Agents: Dynamically call chains based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c19db4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-search-results) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n",
      "Installing collected packages: google-search-results\n",
      "  Running setup.py install for google-search-results: started\n",
      "  Running setup.py install for google-search-results: finished with status 'done'\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: google-search-results is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d22c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba25bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0740ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"21a5aa40d8885c464aab2c4856f5ec6e8f23490ba3d649c0af9e3428dfa5372f\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b20f48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2cf54",
   "metadata": {},
   "source": [
    "See list of agents types [here](https://langchain.readthedocs.io/en/latest/modules/agents/agents.html?highlight=zero-shot-react-description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89728919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the chief minister of Kerala is and how many years until they reach 100.\n",
      "Action: Search\n",
      "Action Input: \"Chief Minister of Kerala\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPinarayi Vijayan\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out how old Pinarayi Vijayan is.\n",
      "Action: Search\n",
      "Action Input: \"Pinarayi Vijayan age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m77 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate how many more years until Pinarayi Vijayan is 100.\n",
      "Action: Calculator\n",
      "Action Input: 100 - 77\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 23\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Pinarayi Vijayan will be 100 years old in 23 years.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pinarayi Vijayan will be 100 years old in 23 years.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the chief minister of Kerala? how many more years before their age become 100?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808dc66",
   "metadata": {},
   "source": [
    "### Memory: Add state to chains and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc3294d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "397ac43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9823cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. My name is AI. What's your name?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3d547bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb71a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You said \"Hi there!\"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d7daf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:  You said \"Hi there!\"\n",
      "Human: what is an alternative phrase in hindi for the first thing I said to you?\n",
      "AI:  I'm sorry, I don't know.\n",
      "Human: what is an alternative phrase in spanish for the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The alternative phrase in Spanish for the first thing you said to me is \"Â¡Hola!\"'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is an alternative phrase in spanish for the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3934501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
